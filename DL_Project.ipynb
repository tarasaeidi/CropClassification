{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"b3doEFRiNXJ3"},"outputs":[],"source":["from google.colab import files\n","files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C38w2OUp1vuT"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"mnt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZs1_qRI10Kq"},"outputs":[],"source":["%cd \"mnt/My Drive/Colab Notebooks\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TwOIpTm315sJ"},"outputs":[],"source":["!pip install import-ipynb\n","!pip install torchnet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AXpsVSR446Ik"},"outputs":[],"source":["import torch\n","import torch.utils.data as data\n","import torchnet as tnt\n","import numpy as np\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix\n","import os\n","import json\n","import pickle as pkl\n","import argparse\n","import pprint\n","\n","from models.stclassifier import PseTae\n","from dataset import PixelSetData, PixelSetData_preloaded\n","from learning.focal_loss import FocalLoss\n","from learning.weight_init import weight_init\n","from learning.metrics import mIou, confusion_matrix_analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"etWPrisH49Kc"},"outputs":[],"source":["def train_epoch(model, optimizer, criterion, data_loader, device, config):\n","    acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\n","    loss_meter = tnt.meter.AverageValueMeter()\n","    y_true = []\n","    y_pred = []\n","\n","    for i, (x, y) in enumerate(data_loader):\n","\n","        y_true.extend(list(map(int, y)))\n","\n","        x = recursive_todevice(x, device)\n","        y = y.to(device)\n","\n","        optimizer.zero_grad()\n","        out = model(x)\n","        loss = criterion(out, y.long())\n","        loss.backward()\n","        optimizer.step()\n","\n","        pred = out.detach()\n","        y_p = pred.argmax(dim=1).cpu().numpy()\n","        y_pred.extend(list(y_p))\n","        acc_meter.add(pred, y)\n","        loss_meter.add(loss.item())\n","\n","        if (i + 1) % config['display_step'] == 0:\n","            print('Step [{}/{}], Loss: {:.4f}, Acc : {:.2f}'.format(i + 1, len(data_loader), loss_meter.value()[0],\n","                                                                    acc_meter.value()[0]))\n","\n","    epoch_metrics = {'train_loss': loss_meter.value()[0],\n","                     'train_accuracy': acc_meter.value()[0],\n","                     'train_IoU': mIou(y_true, y_pred, n_classes=config['num_classes'])}\n","\n","    return epoch_metrics\n","\n","\n","def evaluation(model, criterion, loader, device, config, mode='val'):\n","    y_true = []\n","    y_pred = []\n","\n","    acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\n","    loss_meter = tnt.meter.AverageValueMeter()\n","\n","    for (x, y) in loader:\n","        y_true.extend(list(map(int, y)))\n","        x = recursive_todevice(x, device)\n","        y = y.to(device)\n","\n","        with torch.no_grad():\n","            prediction = model(x)\n","            loss = criterion(prediction, y)\n","\n","        acc_meter.add(prediction, y)\n","        loss_meter.add(loss.item())\n","\n","        y_p = prediction.argmax(dim=1).cpu().numpy()\n","        y_pred.extend(list(y_p))\n","\n","    metrics = {'{}_accuracy'.format(mode): acc_meter.value()[0],\n","               '{}_loss'.format(mode): loss_meter.value()[0],\n","               '{}_IoU'.format(mode): mIou(y_true, y_pred, config['num_classes'])}\n","\n","    if mode == 'val':\n","        return metrics\n","    elif mode == 'test':\n","        return metrics, confusion_matrix(y_true, y_pred, labels=list(range(config['num_classes'])))\n","\n","\n","def get_loaders(dt, kfold, config):\n","    indices = list(range(len(dt)))\n","    np.random.shuffle(indices)\n","\n","    kf = KFold(n_splits=kfold, shuffle=False)\n","    indices_seq = list(kf.split(list(range(len(dt)))))\n","    ntest = len(indices_seq[0][1])\n","\n","    loader_seq = []\n","    for trainval, test_indices in indices_seq:\n","        trainval = [indices[i] for i in trainval]\n","        test_indices = [indices[i] for i in test_indices]\n","\n","        validation_indices = trainval[-ntest:]\n","        train_indices = trainval[:-ntest]\n","\n","        train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n","        validation_sampler = data.sampler.SubsetRandomSampler(validation_indices)\n","        test_sampler = data.sampler.SubsetRandomSampler(test_indices)\n","\n","        train_loader = data.DataLoader(dt, batch_size=config['batch_size'],\n","                                       sampler=train_sampler,\n","                                       num_workers=config['num_workers'])\n","        validation_loader = data.DataLoader(dt, batch_size=config['batch_size'],\n","                                            sampler=validation_sampler,\n","                                            num_workers=config['num_workers'])\n","        test_loader = data.DataLoader(dt, batch_size=config['batch_size'],\n","                                      sampler=test_sampler,\n","                                      num_workers=config['num_workers'])\n","\n","        loader_seq.append((train_loader, validation_loader, test_loader))\n","    return loader_seq\n","\n","\n","def recursive_todevice(x, device):\n","    if isinstance(x, torch.Tensor):\n","        return x.to(device)\n","    else:\n","        return [recursive_todevice(c, device) for c in x]\n","\n","\n","def prepare_output(config):\n","    os.makedirs(config['res_dir'], exist_ok=True)\n","    for fold in range(1, config['kfold'] + 1):\n","        os.makedirs(os.path.join(config['res_dir'], 'Fold_{}'.format(fold)), exist_ok=True)\n","\n","\n","def checkpoint(fold, log, config):\n","    with open(os.path.join(config['res_dir'], 'Fold_{}'.format(fold), 'trainlog.json'), 'w') as outfile:\n","        json.dump(log, outfile, indent=4)\n","\n","\n","def save_results(fold, metrics, conf_mat, config):\n","    with open(os.path.join(config['res_dir'], 'Fold_{}'.format(fold), 'test_metrics.json'), 'w') as outfile:\n","        json.dump(metrics, outfile, indent=4)\n","    pkl.dump(conf_mat, open(os.path.join(config['res_dir'], 'Fold_{}'.format(fold), 'conf_mat.pkl'), 'wb'))\n","\n","\n","def overall_performance(config):\n","    cm = np.zeros((config['num_classes'], config['num_classes']))\n","    for fold in range(1, config['kfold'] + 1):\n","        cm += pkl.load(open(os.path.join(config['res_dir'], 'Fold_{}'.format(fold), 'conf_mat.pkl'), 'rb'))\n","\n","    _, perf = confusion_matrix_analysis(cm)\n","\n","    print('Overall performance:')\n","    print('Acc: {},  IoU: {}'.format(perf['Accuracy'], perf['MACRO_IoU']))\n","\n","    with open(os.path.join(config['res_dir'], 'overall.json'), 'w') as file:\n","        file.write(json.dumps(perf, indent=4))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNvzd8V-bPno"},"outputs":[],"source":["import sys\n","sys.argv=['']\n","del sys"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xcp8o0iE0FK2"},"outputs":[],"source":["def main(config):\n","    np.random.seed(config['rdm_seed'])\n","    torch.manual_seed(config['rdm_seed'])\n","    prepare_output(config)\n","\n","    mean_std = pkl.load(open(config['']+ '/S2-2017-T31TFM-meanstd.pkl', 'rb'))\n","    extra = 'geomfeat' if config['geomfeat'] else None\n","\n","    if config['preload']:\n","        dt = PixelSetData_preloaded(config['dataset_folder'], labels='label_44class', npixel=config['npixel'],\n","                          sub_classes=[1, 3, 4, 5, 6, 8, 9, 12, 13, 14, 16, 18, 19, 23, 28, 31, 33, 34, 36, 39],\n","                          norm=mean_std,\n","                          extra_feature=extra)\n","    else:\n","        dt = PixelSetData(config['dataset_folder'], labels='label_44class', npixel=config['npixel'],\n","                          sub_classes=[1, 3, 4, 5, 6, 8, 9, 12, 13, 14, 16, 18, 19, 23, 28, 31, 33, 34, 36, 39],\n","                          norm=mean_std,\n","                          extra_feature=extra)\n","    device = torch.device(config['device'])\n","\n","    loaders = get_loaders(dt, config['kfold'], config)\n","    for fold, (train_loader, val_loader, test_loader) in enumerate(loaders):\n","        print('Starting Fold {}'.format(fold + 1))\n","        print('Train {}, Val {}, Test {}'.format(len(train_loader), len(val_loader), len(test_loader)))\n","\n","        model_config = dict(input_dim=config['input_dim'], mlp1=config['mlp1'], pooling=config['pooling'],\n","                            mlp2=config['mlp2'], n_head=config['n_head'], d_k=config['d_k'], mlp3=config['mlp3'],\n","                            dropout=config['dropout'], T=config['T'], len_max_seq=config['lms'],\n","                            positions=dt.date_positions if config['positions'] == 'bespoke' else None,\n","                            mlp4=config['mlp4'])\n","\n","        if config['geomfeat']:\n","            model_config.update(with_extra=True, extra_size=4)\n","        else:\n","            model_config.update(with_extra=False, extra_size=None)\n","\n","        model = PseTae(**model_config)\n","\n","        print(model.param_ratio())\n","\n","        model = model.to(device)\n","        model.apply(weight_init)\n","        optimizer = torch.optim.Adam(model.parameters())\n","        criterion = FocalLoss(config['gamma'])\n","\n","        trainlog = {}\n","\n","\n","\n","        best_mIoU = 0\n","        for epoch in range(1, config['epochs'] + 1):\n","            print('EPOCH {}/{}'.format(epoch, config['epochs']))\n","\n","            model.train()\n","            train_metrics = train_epoch(model, optimizer, criterion, train_loader, device=device, config=config)\n","\n","            print('Validation . . . ')\n","            model.eval()\n","            val_metrics = evaluation(model, criterion, val_loader, device=device, config=config, mode='val')\n","\n","            print('Loss {:.4f},  Acc {:.2f},  IoU {:.4f}'.format(val_metrics['val_loss'], val_metrics['val_accuracy'],\n","                                                                 val_metrics['val_IoU']))\n","\n","            trainlog[epoch] = {**train_metrics, **val_metrics}\n","            checkpoint(fold + 1, trainlog, config)\n","\n","            if val_metrics['val_IoU'] >= best_mIoU:\n","                best_mIoU = val_metrics['val_IoU']\n","                torch.save({'epoch': epoch, 'state_dict': model.state_dict(),\n","                            'optimizer': optimizer.state_dict()},\n","                           os.path.join(config['res_dir'], 'Fold_{}'.format(fold + 1), 'model.pth.tar'))\n","\n","        print('Testing best epoch . . .')\n","        model.load_state_dict(\n","            torch.load(os.path.join(config['res_dir'], 'Fold_{}'.format(fold + 1), 'model.pth.tar'))['state_dict'])\n","        model.eval()\n","\n","        test_metrics, conf_mat = evaluation(model, criterion, test_loader, device=device, mode='test', config=config)\n","\n","        print('Loss {:.4f},  Acc {:.2f},  IoU {:.4f}'.format(test_metrics['test_loss'], test_metrics['test_accuracy'],\n","                                                             test_metrics['test_IoU']))\n","        save_results(fold + 1, test_metrics, conf_mat, config)\n","\n","    overall_performance(config)\n","\n","\n","if __name__ == '__main__':\n","\n","    parser = argparse.ArgumentParser()\n","\n","    # Set-up parameters\n","    parser.add_argument('--dataset_folder', default='', type=str,\n","                        help='Path to the folder where the results are saved.')\n","    parser.add_argument('--res_dir', default='./results', help='Path to the folder where the results should be stored')\n","    parser.add_argument('--num_workers', default=8, type=int, help='Number of data loading workers')\n","    parser.add_argument('--rdm_seed', default=1, type=int, help='Random seed')\n","    parser.add_argument('--device', default='cuda', type=str,\n","                        help='Name of device to use for tensor computations (cuda/cpu)')\n","    parser.add_argument('--display_step', default=50, type=int,\n","                        help='Interval in batches between display of training metrics')\n","    parser.add_argument('--preload', dest='preload', action='store_true',\n","                        help='If specified, the whole dataset is loaded to RAM at initialization')\n","    parser.set_defaults(preload=False)\n","\n","    # Training parameters\n","    parser.add_argument('--kfold', default=5, type=int, help='Number of folds for cross validation')\n","    parser.add_argument('--epochs', default=100, type=int, help='Number of epochs per fold')\n","    parser.add_argument('--batch_size', default=128, type=int, help='Batch size')\n","    parser.add_argument('--lr', default=0.001, type=float, help='Learning rate')\n","    parser.add_argument('--gamma', default=1, type=float, help='Gamma parameter of the focal loss')\n","    parser.add_argument('--npixel', default=64, type=int, help='Number of pixels to sample from the input images')\n","\n","    # Architecture Hyperparameters\n","    ## PSE\n","    parser.add_argument('--input_dim', default=10, type=int, help='Number of channels of input images')\n","    parser.add_argument('--mlp1', default='[10,32,64]', type=str, help='Number of neurons in the layers of MLP1')\n","    parser.add_argument('--pooling', default='mean_std', type=str, help='Pixel-embeddings pooling strategy')\n","    parser.add_argument('--mlp2', default='[132,128]', type=str, help='Number of neurons in the layers of MLP2')\n","    parser.add_argument('--geomfeat', default=1, type=int,\n","                        help='If 1 the precomputed geometrical features (f) are used in the PSE.')\n","\n","    ## TAE\n","    parser.add_argument('--n_head', default=4, type=int, help='Number of attention heads')\n","    parser.add_argument('--d_k', default=32, type=int, help='Dimension of the key and query vectors')\n","    parser.add_argument('--mlp3', default='[512,128,128]', type=str, help='Number of neurons in the layers of MLP3')\n","    parser.add_argument('--T', default=1000, type=int, help='Maximum period for the positional encoding')\n","    parser.add_argument('--positions', default='bespoke', type=str,\n","                        help='Positions to use for the positional encoding (bespoke / order)')\n","    parser.add_argument('--lms', default=None, type=int,\n","                        help='Maximum sequence length for positional encoding (only necessary if positions == order)')\n","    parser.add_argument('--dropout', default=0.2, type=float, help='Dropout probability')\n","\n","    ## Classifier\n","    parser.add_argument('--num_classes', default=20, type=int, help='Number of classes')\n","    parser.add_argument('--mlp4', default='[128, 64, 32, 20]', type=str, help='Number of neurons in the layers of MLP4')\n","\n","    config = parser.parse_args()\n","    config = vars(config)\n","    for k, v in config.items():\n","        if 'mlp' in k:\n","            v = v.replace('[', '')\n","            v = v.replace(']', '')\n","            config[k] = list(map(int, v.split(',')))\n","\n","    pprint.pprint(config)\n","    main(config)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DL_Project.ipynb","provenance":[],"authorship_tag":"ABX9TyOAK2hNXEgY4sTyyH15JZ+u"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}